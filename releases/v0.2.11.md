# June 2025 (v0.2.11)

This release introduces the first pieces of AI integration. Mochi now ships with a flexible runtime for calling large language models, a database layer for capturing runs and prompts, and improved tooling for the MCP server and npx installer.

## LLM Runtime and Providers

The new `runtime/llm` package exposes a simple interface for interacting with chat models via `llm.Open`. Providers are selected through a DSN string, making it easy to swap back ends without changing code. Built‑in connectors include OpenAI, Claude, Cohere, Mistral, Gemini, Grok, Ollama, LlamaCPP and Chutes.

## Generate Text Expression

A new experimental `generate text` block can be parsed and executed. At runtime the interpreter collects field values and returns a placeholder response while integration work continues.

## Database Tools

The `tools/db` package provides optional Postgres tables for recording LLM exchanges as well as runs, builds and golden tests. Logging hooks in the MCP server automatically write entries when enabled via the `POSTGRES_DSN` environment variable.

## MCP Improvements

The server logs full error output, disables ANSI colors by default and accepts an optional filename when evaluating code. These changes make it easier to trace problems when running the server in hosted environments.

## Node Installer

`index.js` and `install.js` have been hardened for cross‑platform use. Installation now correctly extracts the prebuilt binary regardless of operating system and surfaces errors when spawning the executable.

