# Jun 2025 (v0.3.0)

Mochi v0.3.0 introduces **first-class generative AI support** through the new `generate text` block. Programs can now
invoke large language models (LLMs) directly from within Mochi code, using natural language prompts to generate text at
runtime.

This release focuses on providing a clean, testable, and configurable interface for AI-driven code generation, while
preserving the simplicity and composability of the language.

## New Language Feature: `generate text`

The `generate text` block allows you to call out to an LLM using a single prompt and receive a string result. The block
behaves like any other expression in the language and can be composed in assignments, functions, or output operations.

### Example

```mochi
let poem = generate text {
  prompt: "Write a haiku about spring"
}
print(poem)
```

The `prompt` must be a string. The result is a string produced by the model in response to the prompt.

## Prompt Composition

You can build prompts dynamically using string expressions:

```mochi
let topic = "rain"
let result = generate text {
  prompt: "Describe the feeling of " + topic
}
```

This enables programmatic generation of content using user input, time of day, or any other computed values.

## Runtime Behavior

The `generate` block uses a default LLM client configured via **environment variables**. This allows you to plug in any
compatible backend without changing code.

### Environment Configuration

| Variable       | Description                                     |
|----------------|-------------------------------------------------|
| `LLM_PROVIDER` | Provider name (e.g., `openai`, `echo`, `local`) |
| `LLM_DSN`      | Connection string or base URL with credentials  |
| `LLM_MODEL`    | Default model name (e.g., `gpt-4`, `mistral`)   |

If not set, `LLM_PROVIDER` defaults to `"echo"` (which returns the prompt as the output). This is useful for testing.

### Example

```bash
LLM_PROVIDER=openai \
LLM_DSN='https://api.openai.com/v1?api_key=sk-...' \
LLM_MODEL=gpt-4 \
mochi run hello.mochi
```

Mochi initializes the default LLM client lazily. If a `generate` block is evaluated and no client has been configured,
it attempts to use the environment to open a connection. Errors are reported at runtime if this fails.

## Testing and Reproducibility

To support reproducible tests, the `generate` block integrates with the `test` framework. Generated output can be
snapshot-tested using `expect` blocks:

```mochi
test "generate greeting" {
  let result = generate text {
    prompt: "Say hello in Japanese"
  }

  expect result == "こんにちは"
}
```

Run tests with `mochi test --update` to regenerate outputs. This ensures consistency across test runs and allows AI
behavior to be versioned alongside code.



